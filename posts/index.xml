<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Richard Jarry</title>
        <link>/posts/</link>
        <description>Recent content in Posts on Richard Jarry</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>Richard Jarry-Randerson</copyright>
        <lastBuildDate>Fri, 10 May 2019 00:00:00 +0000</lastBuildDate>
        <atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Automatic System Genesis</title>
            <link>/posts/genesis/</link>
            <pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate>
            
            <guid>/posts/genesis/</guid>
            <description>Introduction Operating systems for personal computers have drastically evolved over the past few decades. They became modular, thread-aware, architecture-agnostic, capable of handling graphics and virtual environments as well as networking, and much more !
They also branched and forked into thousands of flavors, creating a plethora of compatibility problems. One of these problems is the system installation process.
While relying on different installation tools, all systems follow the same logical steps :</description>
            <content type="html"><![CDATA[

<h2 id="introduction">Introduction</h2>

<p>Operating systems for personal computers have drastically evolved over the past few decades.
They became modular, thread-aware, architecture-agnostic, capable of handling graphics and virtual environments as well as networking, and much more !</p>

<p>They also branched and forked into thousands of flavors, creating a plethora of compatibility problems. One of these problems is the system installation process.</p>

<p>While relying on different installation tools, all systems follow the same logical steps :</p>

<ul>
<li><strong>Bootstrapping</strong> : Using a system to install another one</li>
<li><strong>Provisionning</strong> : Customizing your freshly installed OS</li>
<li><strong>Staging</strong> : Checking your system&rsquo;s behavior and compliance</li>
<li><strong>Shipping</strong> : Copy your sytem into the target machine(s)</li>
</ul>

<p>In this article we&rsquo;ll try to get a high-level solution for this install problem.
The desired solution should be <strong>system-agnostic</strong>, <strong>automatic</strong>, <strong>modular</strong> and <strong>scalable</strong>.
In other words, any distro with the adequate configuration file should be able to install on any
target machine(s).</p>

<p>An Infrastructure Architect&rsquo;s dream ! </br>
Spoiler alert : it&rsquo;s not straightforward.</p>

<p></br></p>

<h2 id="1-bootstrapping">1. Bootstrapping</h2>

<p>Bootstrapping is the first stage of a system install.
Traditionally done using a bootable medium (drive or network card),
it consists of the following steps.</p>

<ul>
<li>Product registration (if applicable)</li>
<li>Language, keyboard and locale setup</li>
<li>Date, time and timezone setup</li>
<li>Network interfaces setup</li>
<li>Disk partitionning</li>
<li>System install</li>
</ul>

<p>Bootstrapping can usually be automated using preseeding files,
but the preseeding file format depends on the target environment.
The preseeding file path needs to be explicitly given to the bootstrapping program,
or must correspond to the default one.</p>

<p>Bootstrapping can be automated using <a href="https://packer.io/">Packer</a> from HashiCorp. <br/>
You can find good tutorials here and there.</p>

<p>I also happen to have a <a href="https://github.com/teuze/prologue">repo</a> about debian bootstrapping using Packer.</p>

<h3 id="1-1-windows-environments">1.1 Windows environments</h3>

<p>Windows environments from Windows XP onwards can be preseeded.</p>

<p>On Windows XP, the file was called <code>winnt.sif</code> and followed a simple ini structure.
Under different sections were only specified arguments to the install procedure.</p>

<pre><code class="language-ini">[Data]
Autopartition=1
UnattendedInstall=Yes
AutomaticUpdates=Yes

[Unattended]
UnattendMode=FullUnattended
OemSkipEula=Yes
FileSystem=NTFS
Repartition=Yes

[...]

[UserData]
ProductKey=
ComputerName=
FullName=
OrgName=
</code></pre>

<p>Since Windows 7, the file is called <code>Autounattend.xml</code> and is a little bit more complex.
There are four phases in the install procedure, and XML verbosity make them untrivial to understand.
Thankfully, the whole file is doumented on <a href="https://docs.microsoft.com/en-us/windows-hardware/manufacture/desktop/automate-windows-setup">Microsoft Docs</a>, and you can also use <a href="https://windowsafg.com">Windows AFG</a>
(online) as well as <a href="https://docs.microsoft.com/en-us/windows-hardware/get-started/adk-install">WADK</a>, the Windows Assessment and Deployment Kit to help you create it.</p>

<p>For the sake of comparison, here is what this XML file looks like :</p>

<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;unattend xmlns=&quot;urn:schemas-microsoft-com:unattend&quot;&gt;
&lt;settings pass=&quot;windowsPE&quot;&gt;
&lt;component name=&quot;Microsoft-Windows-Setup&quot; processorArchitecture=&quot;x86&quot; publicKeyToken=&quot;31bf3856ad364e35&quot; language=&quot;neutral&quot; versionScope=&quot;nonSxS&quot; xmlns:wcm=&quot;http://schemas.microsoft.com/WMIConfig/2002/State&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt;
&lt;Diagnostics&gt;&lt;OptIn&gt;false&lt;/OptIn&gt;&lt;/Diagnostics&gt;
&lt;DiskConfiguration&gt;
&lt;WillShowUI&gt;OnError&lt;/WillShowUI&gt;&lt;Disk wcm:action=&quot;add&quot;&gt;&lt;DiskID&gt;0&lt;/DiskID&gt;
&lt;WillWipeDisk&gt;true&lt;/WillWipeDisk&gt;&lt;CreatePartitions&gt;
&lt;CreatePartition wcm:action=&quot;add&quot;&gt;&lt;Order&gt;1&lt;/Order&gt;&lt;Type&gt;Primary&lt;/Type&gt;&lt;Size&gt;100&lt;/Size&gt;
&lt;/CreatePartition&gt;&lt;CreatePartition wcm:action=&quot;add&quot;&gt;&lt;Order&gt;2&lt;/Order&gt;&lt;Type&gt;Primary&lt;/Type&gt;
&lt;Extend&gt;true&lt;/Extend&gt;&lt;/CreatePartition&gt;&lt;/CreatePartitions&gt;
&lt;...&gt;
&lt;/component&gt;
&lt;...&gt;
&lt;/settings&gt;
</code></pre>

<p><code>Autounattend.xml</code> is automatically used when it&rsquo;s on the root folder of the install media.
Otherwise, it&rsquo;s apparently possible to pass it as an argument from <code>setup.exe</code>, but I personally
never tried it, so you might want to look for a tutorial focusing specifically on this.</p>

<h3 id="1-2-debian-and-derivatives">1.2 Debian and derivatives</h3>

<p>Preseeding on Debian and derivatives is done using <strong>preseed files</strong>.
Those preseed files leverage <code>debian-install</code> commands and act as answers in the install process.
They therefore allow any type of configuration you could have with the graphical installer.
Please note however that some options are non-trivial to find and to apply.
You might have some testing to do !</p>

<p><a href="https://www.debian.org/releases/stable/example-preseed.txt">Here</a> is a preseed example from Debian. <br/>
<a href="https://help.ubuntu.com/lts/installation-guide/example-preseed.txt">Here</a> is a preseed example from Ubuntu. <br/>
Almost identical, aren&rsquo;t they ?</p>

<p>Preseed files need to be explicitly given to the bootloader (<code>grub</code> or <code>isolinux</code> mostly).
You can find on the <a href="https://www.debian.org/releases/stretch/amd64/apb.html">official Debian install guide</a> a chapter on preseeding.
<!-- I also have a [GitHub repository][7] about unattended Ubuntu Server 18.04LTS ISO creation,
check it out ! --></p>

<h3 id="1-3-fedora-and-derivatives">1.3 Fedora and derivatives</h3>

<p>Preseeding on Fedora and derivatives (RHEL, CentOS et al.) is done using <strong>kickstart profiles</strong>.
Kickstart profiles follow a rather basic structure with commands for each bootstrapping step
(<code>network</code>, <code>lang</code>, <code>keyboard</code>, <code>timezone</code>, <code>part</code> and so on).</p>

<pre><code class="language-shell"># OEL7 kickstart baseline installation file
# Simplified, stripped-out version from Bendler's Gist
# Author:       Thomas Bendler &lt;project@bendler-net.de&gt;
# Date:         Fri Feb  5 12:12:46 CET 2016

# Generic installation options
cdrom
text
firstboot --disable
logging --level=info
reboot --eject

# Security settings
auth --enableshadow --passalgo=sha512
firewall --enabled --service=ssh
selinux --permissive

# Network settings
network  --bootproto=dhcp --device=enp0s3 --ipv6=auto --activate
network  --hostname=localhost.localdomain

# Disc settings
zerombr
clearpart --all --initlabel
bootloader --append=&quot; crashkernel=auto&quot; --location=mbr --boot-drive=sda
autopart --type=lvm
ignoredisk --only-use=sda

# User settings (password: hamburg1)
rootpw --iscrypted $6$WYx8jpVu/jAyvXEl$n2aYNqFCFvMWebHVjS.MrDbheQ7AE4zOpfZnWpXq0tnT43MSnMIDzANW8MqltNHfbRaebLlMPodfdObwTbh5g/
user --groups=wheel --homedir=/home/sysdeploy --name=sysdeploy --password=$6$CmofRJck/r0rcYck$De8OqS.OqrFS3BDpnmQsE88aj93KZZtcTdlniXpeGr4HRPUMr9Vl8zBml3JxrabBJiY4a1LGcEv6PSo5bfIwI1 --iscrypted --gecos=&quot;System Deploy&quot;

# Package group and packages that will be installed
%packages
@core
%end

# Final sync
echo &quot;Sync and finalize kickstart installation&quot;
sync
exit 0
%end
</code></pre>

<p><strong>Note</strong> : Ubuntu distros seem to partially support kickstart files starting since 18.04LTS, which is good news considering how easier it is to preseed that way !</p>

<h3 id="1-4-other-operating-systems">1.4 Other operating systems</h3>

<p>I should further investigate the preseeding possibilities for ArchLinux and BSD systems, it&rsquo;s a longer-term goal. As I understand, Arch has built-in support for shell-scripted bootstrapping, but I definitely need to dig a little deeper.</p>

<p></br></p>

<h2 id="2-provisionning">2. Provisionning</h2>

<p>Provisionning is the second stage of the install process and consists in two steps. First, supplemental content such as packages, updates, and add-ons are installed or copied onto the system. Then configuration files are adjusted if necessary in order to adjust to security and usage requirements.</p>

<p>At this point, system scripting tools have become available, so it&rsquo;s easier and quicker to develop and test provisonning routines than it was to create preseeding files. However, system-specific scripts can still be a hassle to maintain, and you have to develop a new set of scripts for each new environment.</p>

<p>This is why orchestration tools are popular : they describe system configuration in a static and system-agnostic file, turning infrastructure into human-readable code. Without that you will have to rely heavily on your local package managment system.</p>

<h3 id="2-1-provisonning-scripts">2.1 Provisonning scripts</h3>

<h4 id="2-1-1-a-unix-shell-example">2.1.1 A UNIX shell example</h4>

<pre><code class="language-shell">#!/bin/bash
# Simple provionning script for a featherweight graphical desktop
# Needs to be launched with administrative priviledges
# Author : Richard Jarry
# Licensed under WTFPL

set -euo pipefail

# 1. Software to install (by theme)

CORE=&quot;bspwm sxhkd lemonbar dmenu&quot;
GUI=&quot;mupdf feh xterm&quot;
CLI=&quot;fish git vim stow tmux&quot;

apt update
apt install $CORE $GUI $CLI

# 2. Configuration files for custom desktop and shell environment

git clone https://github.com/teuze/private-repo.git $HOME/.dotfiles

cd .dotfiles

stow desktop
stow fish
stow tmux
stow vim
</code></pre>

<p>By the way if you want to build your own desktop environment on Linux or Mac,
I highly recommend the <a href="https://reddit.com/r/unixporn/">unixporn channel on reddit</a> (it&rsquo;s SFW).
Oh, and I use <a href="https://www.gnu.org/software/stow/">GNU Stow</a> in this script in order
to track symbolic links and keep my <code>$HOME</code> tidy (<strong>#MariKondo</strong>).</p>

<h4 id="2-1-2-on-windows">2.1.2 On Windows</h4>

<p>Tweaking the environment on Windows doesn&rsquo;t look easy.
Instead of changing system values and breaking stuff I really have no clue about,
I decided to install additional software providing a higher level of comfort and
usability to the platform. I chose :</p>

<ul>
<li><a href="https://chocolatey.org/">Chocolatey</a> as a package manager</li>
<li><a href="https://www.rainmeter.net/">Rainmeter</a> for Desktop customization</li>
<li><a href="https://www.autohotkey.com/">AutoHotkeys</a> for keyboard shortcuts</li>
<li><a href="http://en.ejie.me/">Clover</a> to (finally) get tabs on the Explorer</li>
</ul>

<p>I also use Powershell and WSL (Linux on Windows) to script things when I need to.</br>
Below, a Powershell script to install and put on the <code>PATH</code> Chocolatey.</p>

<pre><code class="language-powershell">$chocoExePath = 'C:\ProgramData\Chocolatey\bin'

if ($($env:Path).ToLower().Contains($($chocoExePath).ToLower())) {
  echo &quot;Chocolatey found in PATH, skipping install...&quot;
  Exit
}

# Add to system PATH
$systemPath = [Environment]::GetEnvironmentVariable('Path',[System.EnvironmentVariableTarget]::Machine)
$systemPath += ';' + $chocoExePath
[Environment]::SetEnvironmentVariable(&quot;PATH&quot;, $systemPath, [System.EnvironmentVariableTarget]::Machine)

# Update local process' path
$userPath = [Environment]::GetEnvironmentVariable('Path',[System.EnvironmentVariableTarget]::User)
if($userPath) {
  $env:Path = $systemPath + &quot;;&quot; + $userPath
} else {
  $env:Path = $systemPath
}

# Run the installer
iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1'))

</code></pre>

<h3 id="2-2-orchestration-tools">2.2 Orchestration tools</h3>

<p>The infrastructure&rsquo;s prodigal sons.</p>

<p><strong>Upsides</strong></p>

<ul>
<li>Orchestration tools are distribution-agnostic up to a certain limit</li>
<li>They are also concurrent (you can configure several machines at once)</li>
<li>Correctly implemented, they always the deliver the same (accurate) result</li>
</ul>

<p><strong>Downside</strong></p>

<p>Orchestration tools tend to only fulfill the specific use-case where you configure
and manage machines remotely. Notable exceptions are <a href="https://www.ansible.com/">Ansible</a> and <a href="https://www.saltstack.com/">SaltStack</a> (but
SaltStack is a meanie because you need to register on their website to get their software).</p>

<p>Also, some orchestrators are agentless, while others are not. </br>
For example, <a href="https://puppet.com/">Puppet</a> and <a href="https://www.chef.io/">Chef</a> need some software to be installed on the target machines
before you can start configuring them, while <a href="https://www.cdi.st/">cdist</a> only needs SSH access and a shell.</p>

<p></br></p>

<h2 id="3-staging">3. Staging</h2>

<p>Staging is the third step in the install process and is very often overlooked.
It consists in checking everything is installed correctly and runs as expected.
Additionally, it can include manual steps that cannot be easily reproduced,
such as direct user interface interaction for example.</p>

<p>The only way to make this kind of manipulations reproducible is to make a snapshot of your system.
On physical machines, this means copying your disk one-on-one and compressing
the resulting file to avoid filling up too much space. On virtual machines,
this is made easier thanks to snapshotting utils, extensible virtual disks,
and bundles such as OVA Files and Vagrant Boxes.
In containers, you can directly stage your system by running it with a persistent volume mount.</p>

<p>Once your snapshot is ready, put it on a server. This can be your local backup system, Vagrant Up, Docker Hub, or really any cloud service suiting your needs.</p>

<h3 id="3-1-physical-machines">3.1 Physical Machines</h3>

<pre><code class="language-shell"># For saving entire disks (with boot sector)
dd if=/dev/sdX status=progress | gzip -c &gt; systemname-version-arch-date.img.gz 

# For saving only a specific partition 
dd if=/dev/sdXN status=progress | gzip -c &gt; systemname-version-arch-date.img.gz 

# Save the snpashot checksum for future use
sha256sum systemname-version-arch-date.gz &gt;&gt; SHA256SUMS

# Backup using rsync, borg, scp, or wadevz
</code></pre>

<p><strong>Note</strong> : It is possible to adjust <code>dd</code> options to make the snapshot less error-prone, but it also makes it slower. Check out the blocksize options in the man pages.
Also, dismount before copy, or you will get copy errors for sure.</p>

<h3 id="3-2-virtual-machines">3.2 Virtual Machines</h3>

<p>On <a href="https://www.virtualbox.org/">VirtualBox</a>, staging is quite straightforward. You can list and edit snapshots
from the command-line, and you can also export the whole machine as an OVA bundle.</p>

<pre><code class="language-shell"># Managing VM snapshots
VBoxManage snapshot list
VBoxManage snapshot take snapname
VBoxManage snapshot restore snapname
VBoxManage snapshot delete snapname

# Export your VM (three possible formats)
VBoxManage export machine-name exportname.ova
VBoxManage export machine-name exportname.ovf
VBoxManage export machine-name exportname.tar.gz
</code></pre>

<p>On <a href="https://www.qemu.org/">QEMU/KVM</a>, since virtual drives and virtual machines are treated separately,
this looked just a little bit more complicated. Hopefully there will be soon
a tool allowing for automatic conversion (maybe there already is?)</p>

<pre><code class="language-shell"># 1. Convert your native QEMU disk file to VDI or VMDK format
qemu-img convert -O vdi input.qcow2 output.vdi
qemu-img convert -O vmdk input.qcow2 output.vmdk

# 2. Get the machine settings and put it on an OVF
virsh dumpxml machinename output.xml
vim output.xml # Change disk path if necessary
mv output.xml output.ovf

# 3. Bundle the lot as an archive
tar cvzf machinename.tar.gz ./*
mv machinename.tar.gz machinename.ova
</code></pre>

<p>Lastly you can also use <a href="https://www.vagrantup.com/">Hashicorp Vagrant</a> to manage your machines.
It supports a lot of formats including cloud images which sounds pretty awesome !</p>

<h3 id="3-3-containers">3.3 Containers</h3>

<p>Staging on Docker is pretty easy with Dockerfiles.</br>
Just read my <a href="../docker">previous article</a> lulz</p>

<p></br></p>

<h2 id="4-shipping">4. Shipping</h2>

<p>Now that we have a virtual or physical disk ready to ship, we just need to bitwise-copy
it on our target. You first need to plug the target hard drive(s) somewhere visible so that
you can issue your final command (here, from an OVA file) :</p>

<pre><code class="language-shell">tar xvf machinename.ova # Should give you machinename in VDI or VMDK
VBoxManage clonehd machinename.vdi machinename.img --format RAW
dd if=machinename.img of=/dev/sdX # replace X with target drive 
rm *.{vdi,ovf,img} # cleanup
</code></pre>

<p></br></p>

<h2 id="conclusion">Conclusion</h2>

<p>Automation sounds like a paradox because it requires a massive time investment.
In our case, I&rsquo;d say this is worth the time spent, because our jobs will likely
make us deploy and reinstall systems quite frequently.</p>

<p>It&rsquo;s also a way to reduce electronical waste, because it allows to repurpose old
or infected computers with a lightweight distribution of your choice.</p>
]]></content>
        </item>
        
        <item>
            <title>A Docker Primer</title>
            <link>/posts/docker/</link>
            <pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate>
            
            <guid>/posts/docker/</guid>
            <description>What is Docker ? Docker is a software overlay allowing its users to develop apps in environments called containers. It leverages kernel-side virtualisation technologies in order to make guests systems run as if they were their own.
Docker differs from lower-level virtualisation engines like VMWare or VirtualBox because Docker containers all share the same kernel, while VBoxes for example use each a completely separate stack, from the emulated BIOS upwards.</description>
            <content type="html"><![CDATA[

<p><img src="https://www.docker.com/sites/default/files/social/docker_facebook_share.png" alt="Docker logo" class="center"></img></p>

<h2 id="what-is-docker">What is Docker ?</h2>

<p>Docker is a software overlay allowing its users to develop apps in environments
called <em>containers</em>. It leverages <a href="https://en.wikipedia.org/wiki/Docker_(software)#Technology">kernel-side virtualisation technologies</a>
in order to make guests systems run as if they were their own.</p>

<p>Docker differs from lower-level virtualisation engines like <a href="https://www.vmware.com">VMWare</a>
or <a href="https://www.virtualbox.org">VirtualBox</a> because Docker containers all share the same kernel,
while VBoxes for example use each a completely separate stack, from the
emulated BIOS upwards.</p>

<p>This allows Docker containers to :</p>

<ul>
<li>Run extremely fast, because they&rsquo;re native and not emulated</li>
<li>Take less HDD space (<a href="https://hub.docker.com/_/debian?tab=tags">vanilla debian weighs around 50MB</a>)</li>
<li>Be easy to build : see Dockerfile examples below.</li>
</ul>

<p>Of course, it also has a few drawbacks :</p>

<ul>
<li>Containers are system specific (no Windows containers on Linux&hellip;)</li>
<li>Security can be a concern, <em>there is actually a lot going on there</em>.</li>
</ul>

<p><a href="https://www.docker.com">Docker</a> is also the name of the very successful company who is developping
the aforementionned solution, as well as a few other services and products
like <code>docker-compose</code> and the Docker Hub which will be presented in more
detail on the next sections.</p>

<h2 id="installing-docker-on-your-system">Installing Docker on your system</h2>

<p>Docker install process greatly varies regarding your host system.
On Windows and Mac, you can get an installer from the official download page,
which will install the whole up-to-date Docker toolset (called Docker Stack).</p>

<p>On Linux, regarding your target distribution, you can either set a repository,
download a packet, or fetch and compile the executables by hand.
</br>
On a Debian Stretch <code>amd64</code> system, you can do as follows.</p>

<pre><code class="language-bash">sudo apt install apt-transport-https ca-certificates
wget https://download.docker.com/linux/debian/gpg -O docker.pub
# Verify integrity using SHA256sum and key fingerprint
sudo apt-key add docker.pub

URL=&quot;https://download.docker.com/linux/debian stretch stable&quot;
sudo echo &quot;deb [arch=amd64] &quot;$URL &gt;&gt; /etc/apt/sources.list
sudo apt update
sudo apt install docker-ce
</code></pre>

<p>For other systems, please have a look at the Docker <a href="https://docs.docker.com">online docs</a>.
Once you&rsquo;ve got Docker on your system, you can check its version by typing
the usual <code>docker -v</code>.</p>

<p><strong>Security warning</strong> : While adding your standard user to the Docker group
can be tempting to avoid constant sudoing when using <code>docker</code>, it is bad
practice to do so because the Docker group basically gives you root rights.
For example, an attacker who compromised your user account could erase
your standard system logs by typing this one-liner.</p>

<pre><code class="language-bash">docker exec alpine --mount /var/log:/root/logs rm -rf ~/logs
</code></pre>

<h2 id="running-your-first-container">Running your first container</h2>

<p>Now you have Docker on your system, let&rsquo;s take quick tour of what&rsquo;s possible.
First we&rsquo;ll search the Docker Hub to get our containers :</p>

<pre><code class="language-bash">sudo docker search alpine
sudo docker search debian
sudo docker search ubuntu
</code></pre>

<p>These commands should each output a list of images vaguely looking like this.</p>

<pre><code>
root@laptop:~# docker search alpine --limit 8
NAME                                   DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED
alpine                                 A minimal Docker image based on Alpine Linux…   5201                [OK]                
mhart/alpine-node                      Minimal Node.js built on Alpine Linux           428                                     
anapsix/alpine-java                    Oracle Java 8 (and 7) with GLIBC 2.28 over A…   406                                     [OK]
alpine/git                             A  simple git container running in alpine li…   79                                      [OK]
kiasaki/alpine-postgres                PostgreSQL docker image based on Alpine Linux   43                                      [OK]
easypi/alpine-arm                      AlpineLinux for RaspberryPi                     32                                      
jfloff/alpine-python                   A small, more complete, Python Docker image …   24                                      [OK]
hermsi/alpine-sshd                     Dockerize your OpenSSH-server upon a lightwe…   18                                      [OK]

</code></pre>

<p>Each list item corresponds to a Docker image. The list also shows the image tags,
popularity, and official status to help you make yourself an idea of how much
trust you can put in what you&rsquo;re about to download.</p>

<p>You can also search this on the <a href="hub.docker.com">Hub Webpage</a> or if you use
<a href="ddg.gg">DuckduckGo</a>, using the associated <code>!docker</code> bang. The web results will
give you more detailed information (image building process, GitHub repo,
and so on) than just a plain CLI search without arguments.</p>

<p>Once you&rsquo;ve decided which image to get, you can download it like this :</p>

<pre><code class="language-bash"># Template : sudo docker pull repo/image:tag
# Repo and tag can be omitted if unambiguous
sudo docker pull alpine
</code></pre>

<p>Docker will then get the corresponding image layers and install the image.
You can find it under <code>/var/lib/docker</code> but it may require a little search.
More on Docker objects and internals on a next article, maybe.</p>

<p>Now you have your image, how about interacting with it ? </br>
Quick terminology tip : a running Docker image is a container.</p>

<pre><code class="language-bash">sudo docker run -it alpine	# Dive inside the container
sudo docker exec alpine &quot;id&quot;	# Execute commands from outside
sudo docker logs alpine		# Get container logs (stdout)
</code></pre>

<p>You will quickly notice a few other things.</p>

<ol>
<li><p>You usually enter inside the container as root, but you may not be able to do
everything the host root user can do. This actually depends on the
container&rsquo;s capabilities, which can be set on startup.
More on this topic in the Security section.</p></li>

<li><p>Inside the running container, you have your own network interfaces, and your
own directory tree. They are de-coupled with the host network and file
system by default, but this can be changed if needed using <code>--network</code>
and <code>--mount</code> options on startup. This however can lead to security
leaks if not properly handled, be sure to check your threat model.</p></li>

<li><p>Once exited, the container is destroyed and any unsaved changes will be lost.</p></li>
</ol>

<p>Let&rsquo;s now try to develop our own customized environment.</p>

<h2 id="building-with-docker">Building with Docker</h2>

<h3 id="docker-images">Docker images</h3>

<p>The canonical way of building images is by writing provisionning scripts called
<em>Dockerfiles</em>. In these files, you specify a base image to start <code>FROM</code>, then
you can <code>COPY</code> stuff into it and <code>RUN</code> scripts inside it until you get to the
expected result.</p>

<p>Then, you can specifiy the first command of your container
at startup : this is done by either <code>CMD</code> or <code>ENTRYPOINT</code>.
The first one passes a shell command, the second one a shell script
(<em>more or less&hellip;</em>)</p>

<p>You can also do other interesting things such as changing your base <code>USER</code>,
setting environment variables in the target system, or using custom arguments.</p>

<p>Here is an example of a simple Dockerfile for network traffic analysis.</p>

<pre><code>FROM alpine:latest

RUN	apk add tcpdump ngrep tshark &amp;&amp; \
	adduser --disabled-password --gecos &quot;&quot; analyser

USER analyzer
WORKDIR /home/analyzer

CMD [&quot;/bin/sh&quot;]
</code></pre>

<p>For each Dockerfile directive, a new image layer is created. For this reason,
<code>RUN</code> commands tend to be very compact, with each instruction linked to the
previous with a double ampersand <code>&amp;&amp;</code>.</p>

<p>I recommend keeping an eye on the <a href="https://docs.docker.com/engine/rference/builder">Dockerfile reference</a>,
on the <a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices">best practice webpage</a> and on the official
<a href="https://docs.docker.com/get-started">Docker tutorial</a> anyway while experimenting with Docker builds.</p>

<p>Once you have your Dockerfile ready, you can just run something like :</p>

<pre><code class="language-bash">sudo docker build -t imagename path/to/Dockerfile
sudo docker images # Check it has been successfully added
sudo docker rmi 1234567890abcdef # In case of overwriting
sudo docker run -it imagename
</code></pre>

<ul>
<li><p>When building several times over the same image, remains of previous
builds appear in the image list without any name. You can use <code>rmi</code>
to delete those if they&rsquo;re not useful anymore.</p></li>

<li><p>Oftentimes, Docker images are not meant to be CLI-interactive by default.
This can be the case when developping a service like a webserver for example.
In that case, the <code>-it</code> option should be discarded.</p></li>

<li><p>Sometimes you&rsquo;ll also want to share your image. In that case, you may either
push it on the Docker Hub or save it to a gzipped archive file.</p></li>
</ul>

<pre><code class="language-bash">sudo docker push user/image	# Requires a Hub account (?)
sudo docker save imagename 	# Missing args to gzip result
</code></pre>

<p>Okay, so now we have a cool custom image, but as you probably noticed,
you can&rsquo;t actually use the installed binaries yet, because you enter
the container as <code>analyzer</code> who has no admin rights.
Even if you delete line 4 in the Dockerfile, you still won&rsquo;t be able
to monitor what&rsquo;s going on over your host interface.</p>

<p>How can we setup the container environment in order to make it work ?</p>

<h3 id="setting-up-the-image-environment">Setting up the image environment</h3>

<p>There are actually two ways of setting up a Docker environment : arguments and
<code>docker-compose</code>. We briefly saw the first one with <code>--network</code> and <code>--mount</code>
options, but there are a lot more. They are listed <a href="https://docs.docker.com/engine/reference/commandline/run/">here</a>.</p>

<p>The second way implies creating a configuration file called <code>docker-compose.yml</code>
and using the <code>docker-compose</code> tool. On Windows and Mac, this tool ships with
Docker by default, but on Linux you may need to install it separately. <br/>
In this case you might want to install it as a container from <a href="https://github.com/docker/compose/releases/download/1.24.0/run.sh">there</a>.</p>

<p>Here is a docker-compose <a href="https://gist.github.com/blackstorm/d446814539daace544d0c9c61e842d18">example</a>. </br>
Here is the docker-compose <a href="https://docs.docker.com/compose/compose-file">reference</a>.</p>

<p>As you can see, docker-compose keywords are almost identical to the previous
arguments. It&rsquo;s just another way to provide the same information.
However, with compose files you can actually automate the building process
and orchestrate the interaction of several Docker containers, which is a big plus.</p>

<p>Below are the files we may use for our project, although we should check
beforehand for security policy compliance. Should this container really be able
to monitor our host interfaces ?</p>

<p><code>Dockerfile</code></p>

<pre><code>FROM alpine:latest

RUN     apk add tcpdump ngrep tshark libcap &amp;&amp; \
        adduser --disabled-password --gecos &quot;&quot; analyzer &amp;&amp; \
        setcap CAP_NET_BIND_SERVICE+ep /usr/bin/ngrep &amp;&amp; \
        setcap CAP_NET_ADMIN+ep /usr/bin/ngrep &amp;&amp; \
        setcap CAP_NET_RAW+ep /usr/bin/ngrep

USER    analyzer
WORKDIR /home/analyzer

CMD     [&quot;/bin/sh&quot;]
</code></pre>

<p><code>docker-compose.yml</code></p>

<pre><code class="language-yaml">version: '2.3'
services:
  main:
    build: .
    image: test
    network_mode: host
    cap_add:
      - NET_RAW
      - NET_ADMIN
      - NET_BIND_SERVICE
    volumes:
      - exchange:/data

volumes:
        exchange:

</code></pre>

<p><code>commandline</code></p>

<pre><code class="language-bash">sudo docker-compose build
sudo docker-compose up		  # For non-interactive containers
sudo docker-compose run main	  # For interactive containers like ours
</code></pre>

<h2 id="wrapping-up-docker-development-workflow">Wrapping up : Docker development workflow</h2>

<ul>
<li>Pull a base image</li>
<li>Work on it with a Dockerfile</li>
<li>Build it (and clean previous remains)</li>
<li>Share it using the Hub or gzipped archives</li>
<li>Run it with arguments or using <code>docker-compose</code></li>
</ul>

<p>And a summary video :</p>

<iframe width="420" height="285" src="https://www.youtube.com/embed/YFl2mCHdv24"></iframe>

<h2 id="docker-security-good-practice">Docker security good practice</h2>

<p>Let&rsquo;s call it &ldquo;okay practice&rdquo; instead and define it in simple terms :</p>

<ul>
<li><p>Design and build a security model for your system as soon as possible,
and audit regularly. This means code audit, pentesting, and architecture
review. A. Shostack has published an <a href="https://threatmodelingbook.com/">excellent guide</a> about
threat modelling I advise anyone to read, and you might also find
interesting info about the subject there.</p></li>

<li><p>Don&rsquo;t blindly trust your base image. Check the build and the runtime
environment, and restrict every unecessary right and cap you can.
You can use inspection tools such as <a href="https://linux-audit.com/lynis/">Lynis</a>, <a href="https://github.com/anchore/anchore-engine">Anchore</a> and
<a href="http://openvas.org/">OpenVAS</a>, and enforcement tools such as <a href="https://wiki.ubuntu.com/AppArmor">AppArmor</a>,
<a href="https://www.nsa.gov/what-we-do/research/selinux/">SELinux</a>, <a href="http://tomoyo.osdn.jp/">Tomoyo</a> and <a href="https://aide.github.io/">AIDE</a>.</p></li>

<li><p>Check for vulnerabilities in your software stack by reading <a href="https://cve.mitre.org/">CVE</a> news
and patch/update anytime there&rsquo;s a critical security bug. Be sure to
also check compliance using for example <a href="https://github.com/cismirror/benchmarks">CIS Benchmarks</a>.</p></li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Docker is one of several kernel-level virtualisation software
available today (other solutions include BSD jails and Solaris zones).
Its cross-platform availability and simplicity of use greatly contributed
to the huge popularity it currently has. With such a tool, it becomes
easy to build and seal your software stack by shipping each block as an
independent container on a monitored, system-internal network.</p>

<p>With such a power comes however the responsibilty of clearly defining your
trust zones and securing your accesses, as Docker runs with near-to-root
rights and prerogatives.</p>
]]></content>
        </item>
        
    </channel>
</rss>
